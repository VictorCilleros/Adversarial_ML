# Adversarial_ML
Fair and Explainable Machine Learning : 
- one adversarial attack
- one adversarial defense
- one global explanation method
- one local explanation method
- one causal/counterfactual explanation method
- asses the bias in your model
- a method to mitigate bias
- and explain the sources of bias before and after mitigation.


Use of ART : https://github.com/Trusted-AI/adversarial-robustness-toolbox 

`pip install adversarial-robustness-toolbox`

Dataset download: https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset/download?datasetVersionNumber=2
